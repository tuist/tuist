defmodule Tuist.CommandEvents.Postgres do
  @moduledoc ~S"""
  PostgreSQL-specific implementation for command events operations.
  """
  import Ecto.Query
  import Timescale.Hyperfunctions

  alias Tuist.CommandEvents.Postgres.Event
  alias Tuist.Projects.Project
  alias Tuist.Repo

  def list_command_events(attrs) do
    query = Event.with_analytics(Event)

    {hit_rate_filter, other_filters} = extract_hit_rate_filter(attrs)

    query =
      if hit_rate_filter do
        apply_hit_rate_filter_to_query(query, hit_rate_filter)
      else
        query
      end

    {modified_attrs, query} = handle_hit_rate_sort(other_filters, query)

    {results, meta} = Flop.validate_and_run!(query, modified_attrs, for: Event)

    results = attach_user_account_names(results)

    {results, meta}
  end

  def list_test_runs(attrs) do
    query =
      where(
        Event,
        [e],
        e.name == "test" or
          (e.name == "xcodebuild" and
             (e.subcommand == "test" or e.subcommand == "test-without-building"))
      )

    {results, meta} = Flop.validate_and_run!(query, attrs, for: Event)

    results = attach_user_account_names(results)

    {results, meta}
  end

  def get_command_events_by_name_git_ref_and_project(%{name: name, git_ref: git_ref, project: %Project{id: project_id}}) do
    Repo.all(
      from(e in Event,
        where: e.name == ^name and e.git_ref == ^git_ref and e.project_id == ^project_id,
        select: e
      )
    )
  end

  def get_command_event_by_id(id, opts \\ [])

  def get_command_event_by_id(nil, _opts), do: {:error, :not_found}

  def get_command_event_by_id(id, opts) when is_binary(id) do
    case Integer.parse(id) do
      {int_id, ""} ->
        get_command_event_by_id(int_id, opts)

      _ ->
        get_command_event_by_uuid(id, opts)
    end
  end

  def get_command_event_by_id(id, opts) when is_integer(id) do
    preload = Keyword.get(opts, :preload, user: :account)

    case Repo.one(from(e in Event, where: e.legacy_id == ^id, preload: ^preload)) do
      nil -> {:error, :not_found}
      event -> {:ok, event}
    end
  end

  def get_command_event_by_id(_id, _opts), do: {:error, :not_found}

  defp get_command_event_by_uuid(id, opts) do
    preload = Keyword.get(opts, :preload, user: :account)

    with {:ok, uuid} <- Ecto.UUID.cast(id),
         event when not is_nil(event) <-
           Repo.one(from(e in Event, where: e.id == ^uuid, preload: ^preload)) do
      {:ok, event}
    else
      _ ->
        {:error, :not_found}
    end
  end

  def create_command_event(event_attrs) do
    %Event{}
    |> Event.create_changeset(event_attrs)
    |> Repo.insert!()
    # NOTE: The `id` field is generated by Postgres on insert and not automatically loaded by Ecto, so we have to reload the record.
    |> Repo.reload()
  end

  def account_month_usage(account_id, date \\ DateTime.utc_now()) do
    beginning_of_month = Timex.beginning_of_month(date)

    query =
      from(c in Event,
        join: p in Project,
        on: p.id == c.project_id and p.account_id == ^account_id,
        where: c.created_at >= ^beginning_of_month,
        where:
          fragment("array_length(?, 1) > 0", c.remote_cache_target_hits) or
            fragment("array_length(?, 1) > 0", c.remote_test_target_hits),
        select: %{
          remote_cache_hits_count: count(c.id)
        }
      )

    Repo.one(query)
  end

  def delete_account_events(account_id) do
    query =
      from(c in Event,
        join: p in Project,
        on: c.project_id == p.id,
        where: p.account_id == ^account_id
      )

    Repo.delete_all(query)
  end

  def list_billable_customers do
    raise "Not implemented."
  end

  def get_yesterdays_remote_cache_hits_count_for_customer(_customer_id) do
    raise "Not implemented."
  end

  def delete_project_events(project_id) do
    query = from(c in Event, where: c.project_id == ^project_id)
    Repo.delete_all(query)
  end

  def get_project_last_interaction_data(project_ids) do
    from(ce in Event,
      where: ce.project_id in ^project_ids,
      group_by: ce.project_id,
      select: %{project_id: ce.project_id, last_interacted_at: max(ce.ran_at)}
    )
    |> Repo.all()
    |> Map.new(fn %{project_id: id, last_interacted_at: time} -> {id, time} end)
  end

  def get_all_project_last_interaction_data do
    from(ce in Event,
      group_by: ce.project_id,
      select: %{project_id: ce.project_id, last_interacted_at: max(ce.ran_at)}
    )
    |> Repo.all()
    |> Map.new(fn %{project_id: id, last_interacted_at: time} -> {id, time} end)
  end

  def get_command_event_by_build_run_id(build_run_id) do
    case Repo.get_by(Event, build_run_id: build_run_id) do
      nil -> {:error, :not_found}
      event -> {:ok, event}
    end
  end

  def run_events(project_id, start_date, end_date, opts) do
    query =
      from(e in Event,
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and
            e.project_id == ^project_id
      )

    query
    |> add_filters(opts)
    |> Repo.all()
  end

  def run_average_durations(project_id, start_date, end_date, date_period, time_bucket, name, opts) do
    query =
      from(e in Event,
        group_by: selected_as(^date_period),
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and e.name == ^name and
            e.project_id == ^project_id,
        select: %{
          date: selected_as(time_bucket(e.created_at, ^time_bucket), ^date_period),
          value: avg(e.duration)
        }
      )

    query
    |> add_filters(Keyword.put(opts, :name, name))
    |> Repo.all()
  end

  def run_count(project_id, start_date, end_date, date_period, time_bucket, name, opts) do
    query =
      from(e in Event,
        group_by: selected_as(^date_period),
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and
            e.project_id == ^project_id,
        select: %{
          date: selected_as(time_bucket(e.created_at, ^time_bucket), ^date_period),
          count: count(e)
        }
      )

    query
    |> add_filters(Keyword.put(opts, :name, name))
    |> Repo.all()
  end

  def cache_hit_rate(project_id, start_date, end_date, opts) do
    query =
      from(e in Event,
        where:
          e.project_id == ^project_id and
            e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]),
        select: %{
          cacheable_targets_count: sum(fragment("COALESCE(array_length(?, 1), 0)", e.cacheable_targets)),
          local_cache_hits_count: sum(fragment("COALESCE(array_length(?, 1), 0)", e.local_cache_target_hits)),
          remote_cache_hits_count: sum(fragment("COALESCE(array_length(?, 1), 0)", e.remote_cache_target_hits))
        }
      )

    result =
      query
      |> add_filters(opts)
      |> Repo.one()

    result
  end

  def cache_hit_rates(project_id, start_date, end_date, date_period, time_bucket, opts) do
    query =
      from(e in Event,
        group_by: selected_as(^date_period),
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and
            e.project_id == ^project_id,
        select: %{
          date: selected_as(time_bucket(e.created_at, ^time_bucket), ^date_period),
          cacheable_targets: sum(fragment("COALESCE(array_length(?, 1), 0)", e.cacheable_targets)),
          local_cache_target_hits: sum(fragment("COALESCE(array_length(?, 1), 0)", e.local_cache_target_hits)),
          remote_cache_target_hits: sum(fragment("COALESCE(array_length(?, 1), 0)", e.remote_cache_target_hits))
        }
      )

    query
    |> add_filters(opts)
    |> Repo.all()
  end

  def selective_testing_hit_rate(project_id, start_date, end_date, opts) do
    query =
      from(e in Event,
        where:
          e.project_id == ^project_id and
            e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]),
        select: %{
          test_targets_count: sum(fragment("COALESCE(array_length(?, 1), 0)", e.test_targets)),
          local_test_hits_count: sum(fragment("COALESCE(array_length(?, 1), 0)", e.local_test_target_hits)),
          remote_test_hits_count: sum(fragment("COALESCE(array_length(?, 1), 0)", e.remote_test_target_hits))
        }
      )

    result =
      query
      |> add_filters(opts)
      |> Repo.one()

    result
  end

  def selective_testing_hit_rates(project_id, start_date, end_date, date_period, time_bucket, opts) do
    query =
      from(e in Event,
        group_by: selected_as(^date_period),
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and
            e.project_id == ^project_id,
        select: %{
          date: selected_as(time_bucket(e.created_at, ^time_bucket), ^date_period),
          test_targets: sum(fragment("COALESCE(array_length(?, 1), 0)", e.test_targets)),
          local_test_target_hits: sum(fragment("COALESCE(array_length(?, 1), 0)", e.local_test_target_hits)),
          remote_test_target_hits: sum(fragment("COALESCE(array_length(?, 1), 0)", e.remote_test_target_hits))
        }
      )

    query
    |> add_filters(opts)
    |> Repo.all()
  end

  def count_events_in_period(start_date, end_date) do
    Repo.aggregate(
      from(e in Event,
        where: fragment("? >= ? AND ? <= ?", e.created_at, ^start_date, e.created_at, ^end_date)
      ),
      :count
    )
  end

  def count_all_events do
    Repo.aggregate(from(e in Event, []), :count)
  end

  def run_average_duration(project_id, start_date, end_date, opts) do
    query =
      from(e in Event,
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and
            e.project_id == ^project_id,
        select: avg(e.duration)
      )

    result =
      query
      |> add_filters(opts)
      |> Repo.one()

    case result do
      nil -> 0
      %Decimal{} = decimal -> Decimal.to_float(decimal)
      duration -> duration
    end
  end

  def run_analytics(project_id, start_date, end_date, opts) do
    query =
      from(e in Event,
        where:
          e.created_at > ^NaiveDateTime.new!(start_date, ~T[00:00:00]) and
            e.created_at < ^NaiveDateTime.new!(end_date, ~T[23:59:59]) and
            e.project_id == ^project_id,
        select: %{
          total_duration: sum(e.duration),
          count: count(e),
          average_duration: avg(e.duration)
        }
      )

    result =
      query
      |> add_filters(opts)
      |> Repo.one()

    case result do
      nil ->
        %{total_duration: 0, count: 0, average_duration: 0}

      %{total_duration: nil, count: count, average_duration: nil} ->
        %{total_duration: 0, count: count, average_duration: 0}

      %{total_duration: total, count: count, average_duration: avg} ->
        %{
          total_duration: normalize_decimal_value(total),
          count: count,
          average_duration: normalize_decimal_value(avg)
        }
    end
  end

  defp normalize_decimal_value(nil), do: 0
  defp normalize_decimal_value(%Decimal{} = decimal), do: Decimal.to_float(decimal)
  defp normalize_decimal_value(value), do: value

  # Private functions

  defp extract_hit_rate_filter(%{filters: filters} = attrs) when is_list(filters) do
    {hit_rate_filters, other_filters} = Enum.split_with(filters, &(&1.field == :hit_rate))

    hit_rate_filter =
      Enum.find_value(hit_rate_filters, fn
        %{value: value, op: op} when not is_nil(value) -> {op, value}
        _ -> nil
      end)

    {hit_rate_filter, %{attrs | filters: other_filters}}
  end

  defp extract_hit_rate_filter(attrs), do: {nil, attrs}

  defp handle_hit_rate_sort(%{order_by: order_by, order_directions: directions} = attrs, query)
       when is_list(order_by) and is_list(directions) do
    hit_rate_index = Enum.find_index(order_by, &(&1 == :hit_rate))

    if hit_rate_index && hit_rate_index < length(directions) do
      direction = Enum.at(directions, hit_rate_index)

      {new_order_by, new_directions} =
        remove_hit_rate_from_ordering(order_by, directions, hit_rate_index)

      modified_query = apply_hit_rate_ordering(query, direction)

      {%{attrs | order_by: new_order_by, order_directions: new_directions}, modified_query}
    else
      {attrs, query}
    end
  end

  defp handle_hit_rate_sort(attrs, query), do: {attrs, query}

  defp remove_hit_rate_from_ordering(order_by, directions, hit_rate_index) do
    new_order_by = List.delete_at(order_by, hit_rate_index)
    new_directions = List.delete_at(directions, hit_rate_index)

    if Enum.empty?(new_order_by) do
      {[:ran_at], [:desc]}
    else
      {new_order_by, new_directions}
    end
  end

  defp apply_hit_rate_ordering(query, :desc) do
    order_by(query, [e],
      desc_nulls_last:
        fragment(
          "CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END",
          e.cacheable_targets,
          e.local_cache_target_hits,
          e.remote_cache_target_hits,
          e.cacheable_targets
        )
    )
  end

  defp apply_hit_rate_ordering(query, _direction) do
    order_by(query, [e],
      asc_nulls_first:
        fragment(
          "CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END",
          e.cacheable_targets,
          e.local_cache_target_hits,
          e.remote_cache_target_hits,
          e.cacheable_targets
        )
    )
  end

  defp apply_hit_rate_filter_to_query(query, {op, value}) do
    case op do
      :> ->
        where(
          query,
          [e],
          fragment(
            "COALESCE(CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END, 0) > ?",
            e.cacheable_targets,
            e.local_cache_target_hits,
            e.remote_cache_target_hits,
            e.cacheable_targets,
            ^value
          )
        )

      :>= ->
        where(
          query,
          [e],
          fragment(
            "COALESCE(CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END, 0) >= ?",
            e.cacheable_targets,
            e.local_cache_target_hits,
            e.remote_cache_target_hits,
            e.cacheable_targets,
            ^value
          )
        )

      :< ->
        where(
          query,
          [e],
          fragment(
            "COALESCE(CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END, 0) < ?",
            e.cacheable_targets,
            e.local_cache_target_hits,
            e.remote_cache_target_hits,
            e.cacheable_targets,
            ^value
          )
        )

      :<= ->
        where(
          query,
          [e],
          fragment(
            "COALESCE(CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END, 0) <= ?",
            e.cacheable_targets,
            e.local_cache_target_hits,
            e.remote_cache_target_hits,
            e.cacheable_targets,
            ^value
          )
        )

      :== ->
        where(
          query,
          [e],
          fragment(
            "COALESCE(CASE WHEN array_length(?, 1) > 0 THEN (COALESCE(array_length(?, 1), 0) + COALESCE(array_length(?, 1), 0))::float / array_length(?, 1) * 100 ELSE NULL END, 0) = ?",
            e.cacheable_targets,
            e.local_cache_target_hits,
            e.remote_cache_target_hits,
            e.cacheable_targets,
            ^value
          )
        )

      _ ->
        query
    end
  end

  defp add_filters(query, opts) do
    query = query_with_is_ci_filter(query, opts)

    scheme = Keyword.get(opts, :scheme)

    query =
      case scheme do
        nil -> query
        _ -> where(query, [e], e.scheme == ^scheme)
      end

    category = Keyword.get(opts, :category)

    query =
      case category do
        nil -> query
        _ -> where(query, [e], e.category == ^category)
      end

    status = Keyword.get(opts, :status)

    query =
      case status do
        nil -> query
        _ -> where(query, [e], e.status == ^status)
      end

    add_name_filter(query, opts)
  end

  defp query_with_is_ci_filter(query, opts) do
    is_ci = Keyword.get(opts, :is_ci)

    case is_ci do
      nil -> query
      true -> where(query, [e], e.is_ci == true)
      false -> where(query, [e], e.is_ci == false)
    end
  end

  defp add_name_filter(query, opts) do
    name = Keyword.get(opts, :name)

    case name do
      "test" ->
        where(
          query,
          [e],
          (e.name == "xcodebuild" and
             (e.subcommand == "test" or e.subcommand == "test-without-building")) or
            e.name == "test"
        )

      _ ->
        query
    end
  end

  defp attach_user_account_names(events) do
    user_ids =
      events
      |> Enum.map(& &1.user_id)
      |> Enum.reject(&is_nil/1)
      |> Enum.uniq()

    user_account_map =
      if Enum.empty?(user_ids) do
        %{}
      else
        user_ids
        |> Tuist.Accounts.list_users_with_accounts_by_ids()
        |> Map.new(&{&1.id, &1.account.name})
      end

    Enum.map(events, fn event ->
      user_account_name = Map.get(user_account_map, event.user_id)
      Map.put(event, :user_account_name, user_account_name)
    end)
  end
end
