---
title: "Why We Fell in Love with Elixir: Building Tuist's Future"
category: "learn"
tags: ["elixir", "server"] 
excerpt: "Discover why we chose Elixir to build Tuist's server infrastructure. From Erlang's battle-tested concurrency model to Phoenix LiveView's revolutionary approach to web development, learn how this technology stack enables our small team to build powerful, scalable solutions without complexity."
author: pepicrft
---

[Steve Jobs](https://en.wikipedia.org/wiki/Steve_Jobs) said that [computers are bicycles for the mind](https://www.themarginalian.org/2011/12/21/steve-jobs-bicycle-for-the-mind-1990/). I think programming languages are too. They are tools for expression, to be creative.

At Tuist, we've been huge fans of [Swift](https://www.swift.org/), the most common programming language of the ecosystem we build for. Yet, we always remained open to finding the right programming language or technology that would allow us to express what we wanted to express.

Through Swift, we could express ourselves in terminals. We built Tuist's main CLI and filled some gaps with other open source tools like [Noora](https://github.com/tuist/noora). Through [VitePress](https://vitepress.dev/), a JavaScript-based solution, we could build a documentation website for our community with built-in search, llm.txt generation, in multiple languages. And then the time to build a server came, and with it the decision to choose the best expression tool.

We needed a solution that allowed us to build and maintain a powerful and simple solution with as few resources as possible. Primarily because we were limited in budget, but also because simpler software is easier to reason about and evolve.

At the time, we had come across [Elixir](https://elixir-lang.org/) and immediately felt it was the right tool to express ourselves in a new domain: the web. If you've never heard about or dove into Elixir, you might be curious about what makes Elixir so special and why we are so passionate about it.

In this post, we'll walk you through what made us fall in love with Elixir and the role it's playing in enabling our vision.

## Erlang and Processes

We can't understand Elixir without talking about Erlang. [Erlang](https://www.erlang.org/) is a programming language and runtime created at Ericsson in the 1980s to power their telecommunication networks. It was designed to build highly-concurrent, scalable, and fault-tolerant software. Sound familiar? These needs are common across the modern web applications that we build today. Erlang comprises a runtime (BEAM), a programming language (Erlang), and a set of primitives to architect your apps (OTP - Open Telecom Platform). At the core of Erlang sits the idea of processes upon which almost everything builds. Joe Armstrong captured what led him to processes in his [thesis](https://erlang.org/download/armstrong_thesis_2003.pdf). He refers to it as _Concurrency Oriented Programming_:

*The word concurrency refers to sets of events which happen simultaneously. The real world is concurrent, and consists of a large number of events many of which happen simultaneously. At an atomic level our bodies are made up of atoms, and molecules, in simultaneous motion. At a macroscopic level the universe is populated with galaxies of stars in simultaneous motion.*

*When we perform a simple action, like driving a car along a freeway, we are aware of the fact that there may be several hundreds of cars within our immediate environment, yet we are able to perform the complex task of driving a car, and avoiding all these potential hazards without even thinking about it. In the real world sequential activities are a rarity. As we walk down the street we would be very surprised to find only one thing happening, we expect to encounter many simultaneous events.*

*If we did not have the ability to analyze and predict the outcome of many simultaneous events we would live in great danger, and tasks like driving a car would be impossible. The fact that we can do things which require processing massive amounts of parallel information suggests that we are equipped with perceptual mechanisms which allow us to intuitively understand concurrency without consciously thinking about it.*

*When it comes to computer programming things suddenly become inverted. Programming a sequential chain of activities is viewed the norm, and in some sense is thought of as being easy, whereas programming collections of concurrent activities is avoided as much as possible, and is generally perceived as being difficult.*

*I believe that this is due to the poor support which is provided for concurrency in virtually all conventional programming languages. The vast majority of programming languages are essentially sequential; any concurrency in the language is provided by the underlying operating system, and not by the programming language.*

So the world (and agentic software) is made of concurrent processes that communicate with each other by passing messages. When I read that, I was fascinated. I had never stopped to see the world that way, but I was hooked by the idea.

Processes in Erlang are lightweight and CPU/memory-isolated runtime elements that can communicate by passing messages and form more complex structures holding state, build supervised trees, define error boundaries, and work across environments (among others). This might sound too abstract at this point, but throughout the blog post I'll make it more concrete with examples of how this materializes. But before doing that, and assuming you have some background as a Swift developer, I'd like to make some comparisons first.

## Solving Parallelism

Modern CPU architecture comprises multiple cores, which presents programming languages with the challenge of using them in the most efficient way possible. Some programming languages like [Ruby](https://www.ruby-lang.org/en/) or [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript), which are single-threaded, prevent having to deal with the challenge by binding their runtime to a single thread, solving concurrency but not parallelism. For example, multiple requests can hang waiting for queries to come back from the database, but only one CPU-bound operation can be executed at the same time. Most apps, both server and mobile, are IO-bound, so most of the time is spent waiting for asynchronous IO operations to complete. If you think of iOS apps, many are just a local presentation layer for some remote API—a wrapper of a server. However, some apps might be CPU-bound, and in those cases, you'll want to leverage the architecture of the system as much as possible.

Every programming language solves this problem differently, and every solution comes with its own trade-offs. When you start running code concurrently, along with using resources in the most efficient way possible, programming languages need to solve the problem of memory safety to avoid data races. [Rust](https://www.rust-lang.org/), for instance, proposed a new memory management model based on [ownership](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html). At compile-time, Rust ensures that memory is always valid and safe to access, but it comes at the cost of having a steeper learning curve and overhead when writing Rust code. 

Swift and its predecessor Objective-C offered concurrency primitives like the [Dispatch](https://developer.apple.com/documentation/dispatch) framework. While it allowed developers to run code concurrently and let the internals of the framework decide how the tasks would be scheduled, it didn't prevent data races, which cause applications to blow up at runtime. As I said earlier, since many of the apps that we build these days are IO-bound, any data-race-prone code won't manifest as data races since apps are not highly concurrent. You just schedule an API request, map the JSON to Swift models, and pass it onto the main thread for presentation. But things are different with Apple pushing Swift to the server—a more highly concurrent environment and potentially CPU-bound—where data races can take the whole system down, and where cleaning up concurrent work on request cancellation is a must.

This all leads to [Swift's structured concurrency](https://docs.swift.org/swift-book/documentation/the-swift-programming-language/concurrency/). Apple's proposed model prevents data races by leveraging the build system. As mentioned earlier, there's always a trade-off, and in the case of Swift's model, the safety came at the cost of a new dimension when writing code that's hard to reason about for developers and LLMs. With it, Apple also solved building a structured tree of tasks that allow passing state and also propagate cancellation down the tree, which as said earlier is critical in the context of a server.

Erlang's process-based model is unique. First, you don't need to think about memory management or isolation domains to make your code data-race safe, which means you can gear your mental energy towards solving a problem. Reasoning about process-based concurrency is more of an opt-in thing when the need for optimizations or defining error boundaries arises. This model comes at the challenge of making memory optimization across processes trickier, since processes copy messages when passing them, but most of the time there's no need for that, and when that arises, there are solutions for it. I like to think of Erlang's concurrency as writing concurrent code without thinking about writing concurrent code. It's truly magical.

## Welcome Elixir

How does Elixir connect to all of this, you might wonder? [José Valim](https://twitter.com/josevalim), creator of Elixir, came from the Ruby & Ruby on Rails community motivated by making Ruby use all the CPU cores available. He came across Erlang and fell in love with its principles and foundation, but he realized that the language, the toolchain, and the ecosystem were not as modern as what he was used to from the Ruby world. He decided to build [Elixir](https://elixir-lang.org/), a programming language that compiles to Erlang bytecode to run in the Erlang runtime. So in other words, Erlang and Elixir are two programming languages that compile to run on the Erlang VM. As you can imagine, the language draws a lot of inspiration from Ruby, and in many ways, it feels like writing Ruby but with a more functional touch to it. If you've used [SwiftPM](https://www.swift.org/documentation/package-manager/) or [Cargo (Rust)](https://doc.rust-lang.org/cargo/), the developer experience is similar. You have a build system, `mix`, which takes care of managing your dependencies, building the project, spawning the test runner, or formatting the code, among others.

So with Elixir, you get the power and the simplicity of a battle-tested runtime (Erlang's) with a modern toolchain, language, and ecosystem that makes building for Erlang a true joy.

## Tuist Meets Elixir

Having talked about Elixir, Erlang, and processes, it's time to talk about why Elixir is so special in the context of Tuist. Note that some of the value that I'll touch on is a shared responsibility between Elixir as a programming language and Erlang as a runtime and framework, but I'll refer to it as just Elixir value. A different way to put it is that Elixir is an awesome frontend to Erlang as a top-notch backend. Let's dive into some day-to-day real impacts on how we are building Tuist.

### A Build System That Doesn't Get in Your Way

I see the value in having a compiler, for example to optimize the code for a targeted runtime or do some static type analysis. However, I can't stand when it gets in the way with slow feedback loops or making any solution that builds upon them behave unreliably. At the time of writing, Xcode's build system falls in this category, which is frustrating to see (unreliable incremental builds, SwiftUI previews...). When you've got an idea for something that you'd like to build, that idea has an energy and a momentum that can easily fade away if you have to wait for a few minutes to see the results live. And when you do that several times a day, who knows... maybe you give up on building the feature. We see that as a challenge to solve at Tuist, in the context of building apps, but not something we wanted to be faced with while building the server.

The Elixir build system is an example of how to make build system work without getting in the way. Like any other build system, it'll take some time initially to build your project (i.e., clean build), but once it's built, it magically hot-reloads your changes, making the feedback loops quite short. Is there a bug in one of the web app routes? I change one line of code, and the change is picked up automatically. This is a developer experience we didn't feel like giving up. Additionally, because Elixir is functional, the reconciliation of the changes at runtime leads to expected results. This is a bit trickier in more stateful programming languages where you've got an instance of a class with state in memory, and a new version of that class potentially with a different state.

Moreover, the meta-programming capabilities of Elixir are amazing with compile and runtime code blurred magically. Take Swift for instance and its meta-programming capability, [Swift Macros](https://docs.swift.org/swift-book/documentation/the-swift-programming-language/macros/). You add an annotation to a piece of runtime Swift code, and the compiler stops to shell out to another process passing a SwiftSyntax tree and receiving it back. Because those two processes are detached (build & Swift Macro resolver), the experience of debugging Swift Macros is far from ideal. In Elixir, it's the same build system process that resolves macros, and therefore you can use the same debugging tools that you'd use to debug runtime code. We use macros to [define model schemas](https://github.com/tuist/tuist/blob/main/server/lib/tuist/accounts/user.ex#L18), [routes](https://github.com/tuist/tuist/blob/main/server/lib/tuist_web/router.ex), or localizable strings.

### Read-Eval-Print Loop

Being able to open a console with access to your codebase symbols and the history of executed instructions can make a huge productivity difference in development. For example, locally we can just do the following to debug a particular organization:

```elixir
Tuist.Accounts.get_organization_by_handle("tuist") 
  |> Tuist.Accounts.get_organization_members()
```

One could say that you can come up with a similar query yourself with the help of an LLM, but if we are talking about a function that encapsulates more business logic, then things get trickier. You are forced to either write an entry point to that piece of logic when all you want is to iterate on a new idea that you came up with. The console is also able to hot-reload changes automatically for you, so you can keep typing, always assuming you'll be using the latest version of your code.

This tool can also be used in production, but we use it sparingly only in very exceptional cases and with read-only operations.

### Server-Driven Interactive UI

I talked a lot about processes earlier, and if there's a good example of how cool they are, we need to talk about [Phoenix LiveView](https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html). [Phoenix](https://www.phoenixframework.org/) is the Ruby on Rails of Elixir. It's the web framework that most Elixir projects use to build web apps. When it comes to doing UI, Phoenix proposes a quite unique model, LiveView, which allows us to build dynamic UIs without having to worry about managing API-provided client-side state or dealing with the cost of a JavaScript runtime setup (and its ecosystem).

You might know that there was a time in the web ecosystem when companies proposed that the way to build dynamic web interfaces was to take the frontend to the client, something that they referred to as Single Page Applications (SPAs). The server would serve a raw HTML skeleton that would then download a JavaScript bundle containing the application and the framework to render it in the DOM (e.g., React, Vue, Svelte). While this eased building very interactive UIs, it came at the cost of having to deal with state management on the client and potentially bad performance on low-end devices that suddenly had to load and run giant pieces of JavaScript. This also became the foundation for new problems and solutions, like [GraphQL](https://graphql.org/) and compile-time generation of client-side code based on components' data needs. Complexity compounded to the point where solving complexity became a business and gave rise to businesses like [Vercel](https://vercel.com/), that abstract that complexity away and make money out of doing that for you. I find it bizarre.

If you are used to building Swift apps, this model is the default. You can't get the server to drive the rendering of your SwiftUI view, although there are continuous community attempts to make that happen to escape Apple's release cycle. Regardless, this is different on the web, where the server can render the HTML that the client will draw. The problem is that just a template system would output static stateless UI with buttons and forms here and there, and if you wanted to make the whole thing more interactive, you'd have to resort to either interactivity in small portions of your HTML, something that the ecosystem refers to as islands of interactivity, or jQuery-like pieces of code that imperatively bring the interactivity.

Phoenix solved this beautifully, and although the model can feel too stretched in some scenarios, it solves most of the needs that web apps have. At the core, Phoenix LiveView uses processes. When you open a page, a process is created and bound to your connection, with a state that's then mapped to HTML that's then presented in your browser. And here's where the magic comes. Since the state is in the server, you don't need to deal with and sync state on the client. Any action that escapes the browser-supported actions and that translates into UI change is sent to the server, then the new state is calculated, mapped to a new representation of that state, and Phoenix LiveView takes care of sending the diff to the client, reconciling the changes for you. In other words, it takes the mental model of frameworks like React, Vue, or even SwiftUI, leveraging processes to keep the state on the server, and dealing with the diffing for you, in the same way SwiftUI does when state changes and the new UI gets rendered automatically. It's beautiful. For example, our [preview](https://github.com/tuist/tuist/blob/main/server/lib/tuist_web/live/preview_live.ex) page uses it. You'll notice that we fetch the state, assign it to the socket connection, and then [use it in the template](https://github.com/tuist/tuist/blob/main/server/lib/tuist_web/live/preview_live.html.heex). Because templates are compiled, the runtime has all the information that it needs to be able to optimize the diff that's sent to the client.

Note that this has the caveat that you need an Internet connection, but due to the nature of the Tuist server, we can assume that people will have Internet connection when accessing it.

### Real-Time UI

People are expecting more and more UIs to update in real-time as new data comes in. In the context of Tuist, we'll have a lot of things happening, from a new build that's pushing logs to our server, to a preview that's being built to be shared with other users. We could embrace the traditional model, which we see in many web applications, where in order to get the fresh data you need to refresh the page, but what if we could align with those new real-time expectations?

And here's where once again, Elixir shines. Building on the above example, once you have a Phoenix LiveView process with a state that backs the UI that you are seeing, you have the foundation to let the server drive those updates when data changes. What's required for that is to propagate state changes and get processes to subscribe to it.

I talked before about message passing and how Erlang solves that in its foundation, and I believe this is an amazing example of that. Phoenix provides [PubSub](https://hexdocs.pm/phoenix_pubsub/Phoenix.PubSub.html), whose default adapter leverages Erlang capabilities to discover and distribute messages across nodes. Let's say you are seeing the builds page, and a new build comes in. Erlang could receive a message saying that a new build has been created, and we can have LiveViews subscribed to those events updating their internal state accordingly and sending the diffs to the client.

Try to build that with a different model. Good luck. You'll need some message-passing solution that escapes your runtime, adding complexity to the infrastructure. If you are doing SPA, you'll also need to build or adopt some solution to forward the state from the server down for the client to reconcile the changes. And hopefully, if everything goes well, you'll have this real-time capability. Alternatively, you can build a polling-based solution, where you continuously poll the server for updates, but this increases the load on the server and can lead to delays in receiving updates.

This capability of Erlang is so cool that even companies like [Supabase](https://supabase.com/) have wrapped it in a product offering it as a service, or major players in the industry, like [Discord](https://discord.com/blog/how-discord-scaled-elixir-to-5-000-000-concurrent-users) and [WhatsApp](https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-anton-lavrik-from-whatsapp/), powered part of their infrastructure with it.

At Tuist, we don't leverage it that much yet, but we are going to invest more and more in making all the features more real-time. Note also that this foundation can also be useful to make features collaborative, where multiple people can be interacting with the same state and seeing the same UI. Sound familiar? This is what we see in modern software like Figma.

### Ease of Scaling

We are a small team, so it's important that as the need for scaling comes, we don't need to invest many resources into it. I think everything scales if you pour enough resources into it. We don't have those resources, but luckily, Elixir makes things super easy.

On the development side of things, we can build powerful solutions, like real-time capabilities, collaborative experiences, or UI without a complex setup. We don't have a lot of indirection, nor convoluted solutions that are hard to reason about. Most of our surfaces are a database schema, a small piece of business logic in between, and a LiveView view. We built and open-sourced [Noora](https://github.com/tuist/noora) to help us move even faster by providing us with all the pieces of UI to make building UI feel like LEGO while ensuring a visual consistency that makes Tuist's dashboard stand out among its competitors.

As part of development, we also have a test suite that we need to ensure runs fast and reliably. I talked a lot about processes, but once again, processes help make scaling test suites a breeze. Every test is a different process, and they are scheduled such that they can run in parallel. What this means is that if you want to run your test suite faster, you can solve the problem by throwing more CPU cores at the problem. And CPU cores get cheaper and cheaper.

Now the challenge is that as you parallelize, you might experience some flakiness if there's some shared state. Elixir's functional approach minimizes shared state, but you can still have processes that share state among other processes (e.g., a cache). So you still need to keep an eye out to identify where those parallelization contention points exist and mitigate them. The best of all is that since every test can spawn a process tree, you can define mocks that are scoped to that tree, such that you can fully isolate your mocks, ensuring no state is leaking across tests, being able to fully parallelize with no flakiness at all. Our test suite is small and runs in a decent amount of time, but if the time for optimizing it comes, we know that we can easily scale it up by adding more CPU cores.

Then lastly, we have the production systems. Elixir's concurrent nature allows scaling the system vertically easily. Just throw more memory and CPU as you need. Erlang's scheduler ensures those resources are used in the best way possible. This means we can go a long way until we decide to scale horizontally. In our case, we grow our production system horizontally not to be able to handle more traffic, but to reduce the latency when interacting with our systems, such that a customer in NY doesn't have to go all the way to Frankfurt to get a response from the API. We run our app on [Fly.io](https://fly.io/), which makes adding and removing new machines in different regions easy. They take care of routing the traffic to the closest server. They also make it extremely easy to change the resources of a machine, so adding cores is just one CLI command away.

The awesomeness of Erlang's scaling capabilities revealed that it'd be our database the bottleneck, but luckily, the Postgres ecosystem is moving quite fast with companies like [Supabase](https://supabase.com/) and [Neon](https://neon.tech/) ensuring a replicated global database for high availability and performance.

Now, it's true that you can achieve the same thing with other languages and runtimes with no complexity, but I think no complexity is more of perceived no complexity. The fact that you don't see the complexity doesn't mean it doesn't exist. It means it's abstracted away in libraries or even services that abstract away and charge you to deal with it. Next.js abstracts the mess of the JS ecosystem, and Vercel takes it further by abstracting away some of the complexities of running JS-based web apps. Elixir and Erlang are low complexity by default. It's not that the complexity is hidden, but rather that by low-level design, the complexity doesn't appear. It's beautiful.

### The Ecosystem

And we cannot wrap this blog post without talking about its ecosystem. It's common to hear that the Elixir ecosystem is quite small compared to other ecosystems. But I find that a feature and not a bug. My take on it is that since many challenges that exist in other ecosystems don't exist here, there's less incentive to build libraries or services to solve and charge for solving challenges. While it's true that in the JS ecosystem there's a lot of innovation happening at the speed of light, it's also true that it's a fragile and constantly-changing foundation upon which you don't want to build a business. You want to base a business upon a battle-tested and mature foundation that provides you just with what you need and doesn't change a lot, making you waste time. If things change a lot, you waste your time, and also make LLMs confused because you can't lean on them as pair programming buddies. I can't think of a better example of that than Swift's most recent concurrency model.

Since we started building the Tuist server, we never came across a moment where we said: we need a solution for a problem that doesn't have an ecosystem package. If not in Elixir, we'd find the package in Erlang, which can be incorporated into your build system and called from Elixir. For example, we added [ClickHouse](https://clickhouse.com/) to our infrastructure recently, so we needed an Elixir interface to ClickHouse. Guess what? [Plausible](https://plausible.io/) had built a ClickHouse adapter for Ecto, [ecto_ch](https://github.com/plausible/ecto_ch). [Ecto](https://hexdocs.pm/ecto/Ecto.html) is the go-to DB interface for Elixir. Most recently, we had to make our server an OpenID Connect provider to allow having first-party clients like our CLI and the iOS app, so we could use something like [Boruta](https://github.com/malach-it/boruta_auth), and get it up and running in a matter of days.

Moreover, all the projects are well documented and have a strong community behind them. You can build on packages and trust that they won't be deprecated because the owners moved onto something else. Having great documentation is key in a world of agentic coding, where agents will regularly check the documentation to write code reliably.

## Closing Words

In hindsight, Elixir was the best bicycle for the job of building the Tuist platform. Our 4-person team (3 of which are focused on development) feels extremely productive building new solutions for our ecosystem. Thanks to such a well-designed foundation and integrated toolchain, we can focus on what matters the most: the problems and the solutions that we are building. And when needed, we delegate some of the scaling challenges, like running our server or database globally, to third-party services like Fly.io or Supabase.

Elixir and Erlang have taught us that with the right modeling and building blocks, you can make a whole set of problems and solutions disappear. Erlang's processes are amazing, and while we don't directly interface with them, they manifest through the libraries that we use with solutions that do a lot with little. We can't see ourselves iterating from this dev stack—it's amazing.

There's so much more we could talk about regarding Elixir and Erlang—from the actor model and supervision trees to the incredible fault tolerance and "let it crash" philosophy, from the powerful pattern matching to the elegant pipe operator. We'll do more future deep dives into specific parts of the ecosystem, exploring topics like OTP (Open Telecom Platform), the BEAM VM's scheduling magic, distributed systems with Erlang, and how tools like [Livebook](https://livebook.dev/) are pushing the boundaries of interactive development. Stay tuned for those!

Thank you José Valim and the whole ecosystem for gifting us with such a wonderful piece of tech.
